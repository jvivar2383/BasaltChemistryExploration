{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ef9c22e-7c40-4949-a7d2-f44ebf94bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f84d231-6b1a-4eca-b9ba-d989a1fe1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracers = np.array(['Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Ba', 'La', 'Ce', 'Pr',\n",
    "       'Nd', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu',\n",
    "       'Hf', 'Ta', 'Th', 'U', 'Ni'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e89410f-6641-47c6-951e-b55ae6803f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ = r\"/Users/jenifervivar/Documents/GitHub/OceanBasaltML/basalts thesis/src/data/combined_datasets\"\n",
    "combined_df = pd.read_csv(p_)\n",
    "p = \"/Users/jenifervivar/Documents/GitHub/OceanBasaltML/basalts thesis/src/data/variables_target_file\"\n",
    "sampled_df = pd.read_csv(p)\n",
    "X = sampled_df[tracers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582f6b28-3840-4572-b9af-63342c885807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09900ba5-2603-451f-8c6a-fc48b90fbde6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_df[\"Nb/Y\"] = np.round(sampled_df[\"Nb\"])/np.round(sampled_df[\"Y\"])\n",
    "sampled_df[\"FeOT/MgO\"]= np.round(sampled_df[\"FeOT\"])/np.round(sampled_df[\"MgO\"])\n",
    "sampled_df[\"La/Sm\"] = np.round(sampled_df[\"La\"])/np.round(sampled_df[\"Sm\"])\n",
    "sampled_df[\"Zr/Nb\"] = np.round(sampled_df[\"Zr\"])/np.round(sampled_df[\"Nb\"])\n",
    "sampled_df[\"Y/Nb\"]= np.round(sampled_df[\"Y\"])/np.round(sampled_df[\"Nb\"])\n",
    "\n",
    "sampled_df[\"Nb/La\"] = np.round(sampled_df[\"Nb\"])/np.round(sampled_df[\"La\"])\n",
    "sampled_df[\"Th/Yb\"] = np.round(sampled_df[\"Th\"])/np.round(sampled_df[\"Yb\"])\n",
    "sampled_df[\"Zr/Y\"] = np.round(sampled_df[\"Zr\"])/np.round(sampled_df[\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f04a56-cdd9-4b0f-a393-d1f988aaa463",
   "metadata": {},
   "source": [
    "## Running Random Forest without standarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b50d7b1-afd9-4892-83e6-bb27b94574cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=500, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X = sampled_df[col], y = sampled_df[\"Tectonic_setting\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,sampled_df[\"Tectonic_setting\"],\\\n",
    "                                                    test_size=0.3, random_state=100)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "X_bal, y_bal = over_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "labels = X.columns.to_list()\n",
    "rf = RandomForestClassifier(n_estimators = 500, random_state = 1)\n",
    "\n",
    "rf.fit(X_bal, y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad9a2d8-803d-4ff4-88f3-31aadc0e7889",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 5461/5469 [07:44<00:00]        "
     ]
    },
    {
     "ename": "ExplainerError",
     "evalue": "Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 0.647960, while the model output was 0.658000. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExplainerError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sk/km6c1g654036cmvl40zycd0m0000gn/T/ipykernel_1398/533205920.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mSHAP_explainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_bal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# calculating the shap values of the test sample using the explainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mshap_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHAP_explainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# converting the test samples to a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_shap_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_additivity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_additivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36massert_additivity\u001b[0;34m(self, phi, model_output)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                 \u001b[0mcheck_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0mcheck_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36mcheck_sum\u001b[0;34m(sum_val, model_output)\u001b[0m\n\u001b[1;32m    536\u001b[0m                            \u001b[0;34m\" was %f, while the model output was %f. If this difference is acceptable\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                            \u001b[0;34m\" you can set check_additivity=False to disable this check.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mExplainerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExplainerError\u001b[0m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 0.647960, while the model output was 0.658000. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# sampling data from the training and test set to reduce time-taken\n",
    "#X_train_sample = shap.sample(X_bal, 200)\n",
    "#X_test_sample = shap.sample(X_test, 40)\n",
    "\n",
    "# creating the KernelExplainer using the logistic regression model and training sample\n",
    "SHAP_explainer = shap.TreeExplainer(rf, X_bal)\n",
    "# calculating the shap values of the test sample using the explainer \n",
    "shap_vals = SHAP_explainer.shap_values(X_bal)\n",
    "\n",
    "# converting the test samples to a dataframe \n",
    "# this is necessary for non-tabular data in order for the visualisations \n",
    "# to include feature value\n",
    "colour_test = pd.DataFrame(X_test_sample.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51577f3c-7997-48ee-a7a1-daee258c11d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 20739/20745 [35:41<00:00]        "
     ]
    }
   ],
   "source": [
    "import shap\n",
    "SHAP_explainer = shap.TreeExplainer(rf, X_bal)\n",
    "shap_vals = SHAP_explainer.shap_values(X_bal, check_additivity=False)\n",
    "\n",
    "# converting the test samples to a dataframe \n",
    "# this is necessary for non-tabular data in order for the visualisations \n",
    "# to include feature value\n",
    "colour_test = pd.DataFrame(X_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf845f19-04ba-47fa-adb8-6565843e723f",
   "metadata": {},
   "source": [
    "the SHAP value for a specific feature i is just the difference between the expected model output and the partial dependence plot at the feature’s value $x_{i}$:\n",
    "\n",
    "By default a SHAP bar plot will take the mean absolute value of each feature over all the instances (rows) of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba724c9-fc42-4802-a225-6d14150778a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(linear_lr.predict_proba, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "480dd2c9-ff3f-482a-a286-fc74378dd8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 20738/20745 [37:46<00:00]        "
     ]
    },
    {
     "ename": "ExplainerError",
     "evalue": "Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 0.142000, while the model output was 0.136000. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExplainerError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sk/km6c1g654036cmvl40zycd0m0000gn/T/ipykernel_6613/3635734799.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHAP_explainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, y, interactions, check_additivity)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minteractions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_additivity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_additivity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapproximate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapproximate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put outputs at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_shap_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_additivity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_additivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36massert_additivity\u001b[0;34m(self, phi, model_output)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                 \u001b[0mcheck_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0mcheck_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36mcheck_sum\u001b[0;34m(sum_val, model_output)\u001b[0m\n\u001b[1;32m    536\u001b[0m                            \u001b[0;34m\" was %f, while the model output was %f. If this difference is acceptable\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                            \u001b[0;34m\" you can set check_additivity=False to disable this check.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mExplainerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExplainerError\u001b[0m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 0.142000, while the model output was 0.136000. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(rf, X_bal)\n",
    "shap_values_2 = explainer(X_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df03b0d4-e4de-46c7-bbd6-80e121aad713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676b8aa-daac-4a39-8298-ffe66bdfd6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b3db522-41b7-4445-b2aa-6cf5c70cc844",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'base_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sk/km6c1g654036cmvl40zycd0m0000gn/T/ipykernel_6613/1588419656.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaterfall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_display\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/plots/_waterfall.py\u001b[0m in \u001b[0;36mwaterfall\u001b[0;34m(shap_values, max_display, show)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mioff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mbase_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_data\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'base_values'"
     ]
    }
   ],
   "source": [
    "sample_ind = 10\n",
    "shap.plots.waterfall(shap_values_2, max_display=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa59780-082c-41db-9d71-8ae4c4b5a711",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the beeswarm plot requires Explanation object as the `shap_values` argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sk/km6c1g654036cmvl40zycd0m0000gn/T/ipykernel_6613/3981558336.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeeswarm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/plots/_beeswarm.py\u001b[0m in \u001b[0;36mbeeswarm\u001b[0;34m(shap_values, max_display, order, clustering, cluster_threshold, color, axis_color, alpha, show, log_scale, color_bar, plot_size, color_bar_label)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExplanation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the beeswarm plot requires Explanation object as the `shap_values` argument\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: the beeswarm plot requires Explanation object as the `shap_values` argument"
     ]
    }
   ],
   "source": [
    "shap.plots.beeswarm(shap_values_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41c15b48-b24b-471b-a446-6fa7a5af27a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.summary_plot(shap_vals, colour_test, feature_names=tracers, class_names= rf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbdc429-834d-4123-8a7b-79d19adab7f6",
   "metadata": {},
   "source": [
    "## Same on Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2da3545a-d786-4efe-bdd4-216b5f945558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The max_iter was reached which means the coef_ did not converge\n",
      "X has feature names, but LogisticRegression was fitted without feature names\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_standard = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "X_bal, y_bal = over_sampler.fit_resample(x_standard, y_train)\n",
    "\n",
    "lr = LogisticRegression(C= 100, random_state = 1, multi_class = 'ovr', solver = 'saga', penalty='l1', max_iter=5000)\n",
    "lr.fit(X_bal, y_bal)\n",
    "y_result = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3dffa01-4e0c-486a-a08b-f7cadabef634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 6915 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6a2a71a7a041ba98b9041bb4ee4888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing line 1 of /Users/jenifervivar/opt/anaconda3/lib/python3.9/site-packages/google_auth-1.4.2-py2.7-nspkg.pth:\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"/Users/jenifervivar/opt/anaconda3/lib/python3.9/site.py\", line 169, in addpackage\n",
      "      exec(line)\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"<frozen importlib._bootstrap>\", line 562, in module_from_spec\n",
      "  AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\n",
      "Remainder of file ignored\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sk/km6c1g654036cmvl40zycd0m0000gn/T/ipykernel_6613/144818850.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKernelExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_bal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/explainers/_kernel.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_instance_with_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mexplanations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gc_collect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/explainers/_kernel.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;31m# execute the model on the synthetic samples we have created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# solve then expand the feature importance (Shapley value) vector to contain the non-varying features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shap/explainers/_kernel.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0meyVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                 \u001b[0meyVal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meyVal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "explainer = shap.KernelExplainer(lr.predict_proba, X_bal)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ce844-81ba-4a02-a706-df63b2d7f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAP_explainer = shap.TreeExplainer(rf, X_bal)\n",
    "shap_vals = SHAP_explainer.shap_values(X_bal, check_additivity=False)\n",
    "\n",
    "# converting the test samples to a dataframe \n",
    "# this is necessary for non-tabular data in order for the visualisations \n",
    "# to include feature value\n",
    "colour_test = pd.DataFrame(X_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d42c1-800e-44e3-a2a2-d3d13c9c714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
